{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6ab4402",
   "metadata": {},
   "source": [
    "# 4. Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d05f16",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The Reflection pattern introduces self-evaluation capabilities to agent systems. This architecture enables agents to:\n",
    "\n",
    "- **Analyze their own outputs** for quality and completeness\n",
    "- **Make iterative improvements** by regenerating responses\n",
    "- **Ensure requirements are met** before finalizing responses\n",
    "- **Implement quality control** through automated review cycles\n",
    "\n",
    "![Reflection Architecture](../docs/reflection.png)\n",
    "\n",
    "### Key Components\n",
    "\n",
    "1. **Generator Agent**: Creates initial responses to user queries\n",
    "2. **Reflection Agent**: Evaluates the quality and completeness of responses\n",
    "3. **Feedback Loop**: Allows for regeneration based on reflection results\n",
    "4. **Quality Criteria**: Structured evaluation framework\n",
    "\n",
    "This pattern is particularly useful for:\n",
    "- **Complex reasoning tasks** requiring multiple iterations\n",
    "- **Content creation** with quality standards\n",
    "- **Customer service** where accuracy is critical\n",
    "- **Educational applications** with learning feedback\n",
    "\n",
    "## Implementation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa434df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from typing import Literal\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph import END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a0b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(model=\"gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6276a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def travel_advice(state) -> str:\n",
    "    print(\"Node: Travel Advice\")\n",
    "    response = llm.invoke(input=state[\"messages\"])\n",
    "\n",
    "    return {\n",
    "        \"messages\": [response]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a234371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "class ReflectionOutput(BaseModel):\n",
    "    \"\"\"You reflect on the conversation and checks if input contains the requested topic.\"\"\"\n",
    "    topic: str\n",
    "    contains_info: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15de795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection(state) -> Command[Literal[\"travel_advice\", \"__end__\"]]:\n",
    "    print(\"Node: Reflection\")\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    structured_llm = llm.with_structured_output(ReflectionOutput)\n",
    "\n",
    "    topic_check_list = [\"sports\", \"cultural\", \"historical\"]\n",
    "    validations = []\n",
    "    for topic in topic_check_list:\n",
    "        response = structured_llm.invoke(input=[\n",
    "            SystemMessage(content=f\"You are a content expert, and validate if a messages contains information about topic \\\"{topic}\\\"?\"),\n",
    "            last_message\n",
    "        ])\n",
    "        validations.append(response)\n",
    "\n",
    "    missing_topics = [response for response in validations if not response.contains_info]\n",
    "    print(f\"Missing topics: {[response.topic for response in missing_topics]}\")\n",
    "\n",
    "    if len(missing_topics) > 0:\n",
    "        return Command(\n",
    "            goto=\"travel_advice\",\n",
    "            update={\"messages\": [AIMessage(content=\"Extend output with information about following topics: \" \n",
    "                                           + \", \".join([response.topic for response in missing_topics]))]}\n",
    "        )\n",
    "    else:\n",
    "        return Command(\n",
    "            goto=END\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d0eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"travel_advice\", travel_advice)\n",
    "builder.add_node(\"reflection\", reflection)\n",
    "\n",
    "builder.add_edge(START, \"travel_advice\")\n",
    "builder.add_edge(\"travel_advice\", \"reflection\")\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6948ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(graph.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446e702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant that gives travel advice based on the user's input.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Perth\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4a9041",
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in messages:\n",
    "    msg.pretty_print()\n",
    "\n",
    "async for event in graph.astream(input={\"messages\": messages}, stream_mode=\"updates\"):\n",
    "    for node in graph.nodes.keys():\n",
    "        node_output = event.get(node, {})\n",
    "        if node_output is not None:\n",
    "            output_msgs = node_output.get(\"messages\", [])\n",
    "            for msg in output_msgs:\n",
    "                msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672f5da5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
