{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d518d075",
   "metadata": {},
   "source": [
    "# 1. Simple LLM Call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae09436",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "An LLM call is the simplest agent architecture available. It represents a basic conversational AI that:\n",
    "- **Cannot execute any actions** (no tool calling, no external API access)\n",
    "- **Only returns text tokens** that fit your prompt\n",
    "- **Operates in a stateless manner** for single interactions\n",
    "\n",
    "This pattern is ideal for:\n",
    "- Simple question-answering scenarios\n",
    "- Content generation tasks\n",
    "- Text processing and analysis\n",
    "- Scenarios where you don't need external data or actions\n",
    "\n",
    "## Implementation Steps\n",
    "\n",
    "Let's walk through building a simple LLM agent step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8630f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d478aad6",
   "metadata": {},
   "source": [
    "### Step 1: Initialize the Language Model\n",
    "\n",
    "We'll use Azure OpenAI's GPT-4.1-mini model. This creates a connection to the language model that we'll use for generating responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1f16949",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(model=\"gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19416f7",
   "metadata": {},
   "source": [
    "### Step 2: Construct the Message Sequence\n",
    "\n",
    "We create a conversation using two types of messages:\n",
    "- **SystemMessage**: Defines the AI's role and behavior (acts as context/instructions)\n",
    "- **HumanMessage**: Represents the user's input/query\n",
    "\n",
    "The system message shapes how the AI responds, while the human message provides the actual query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39ceb23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"You are a travel expert. Based on the user's input, suggest 1 travel destination.\"),\n",
    "    HumanMessage(\"Cat\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4a3b13",
   "metadata": {},
   "source": [
    "### Step 3: Execute the LLM Call\n",
    "\n",
    "Now we invoke the language model with our message sequence. The `invoke()` method:\n",
    "- Sends our messages to the LLM\n",
    "- Receives the AI's response\n",
    "- Returns an AIMessage object containing the response\n",
    "\n",
    "We append the response to our message history to maintain conversation context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66240557",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = llm.invoke(input=messages)\n",
    "messages.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034b7559",
   "metadata": {},
   "source": [
    "### Step 4: Display the Conversation\n",
    "\n",
    "Using `pretty_print()` gives us a formatted view of the entire conversation flow:\n",
    "- The system instructions\n",
    "- The user's question  \n",
    "- The AI's response\n",
    "\n",
    "This helps visualize how the conversation unfolds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b16921fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a travel expert. Based on the user's input, suggest 1 travel destination.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Cat\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "If you love cats, consider visiting **Kyoto, Japan**. The city is known for its beautiful temples and traditional culture, but also for the famous Cat Island, Tashirojima, which is not far from there. Tashirojima is a small island where cats roam freely and are considered good luck. You can enjoy a peaceful visit surrounded by friendly felines in a serene setting.\n"
     ]
    }
   ],
   "source": [
    "for msg in messages:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion_section",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "This simple LLM call pattern demonstrates:\n",
    "\n",
    "1. **Basic Structure**: System message + Human message â†’ AI response\n",
    "2. **Stateless Operation**: Each call is independent (unless you maintain message history)\n",
    "3. **No External Actions**: The AI can only generate text, not perform actions\n",
    "\n",
    "## When to Use This Pattern\n",
    "\n",
    "- **Content Generation**: Blog posts, summaries, creative writing\n",
    "- **Simple Q&A**: Direct questions that don't require external data\n",
    "- **Text Processing**: Translation, formatting, analysis\n",
    "- **Brainstorming**: Idea generation without execution needs\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "To extend this basic pattern:\n",
    "- **Add Tools**: Enable the agent to perform actions (next notebook: Tool Calling)\n",
    "- **Add Memory**: Maintain conversation history across sessions\n",
    "- **Add Routing**: Direct different types of queries to specialized handlers\n",
    "- **Add Validation**: Implement input/output checking and filtering\n",
    "\n",
    "This foundation will serve as the building block for more complex agent architectures in the following notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
