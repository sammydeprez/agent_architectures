{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea669370",
   "metadata": {},
   "source": [
    "# 2.1 Using Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280f6edd",
   "metadata": {},
   "source": [
    "By binding tools or functions to your llm, the model gets information about those tools, and it will tell you that it wants to execute a tool. Notice the LLM is not going to execute the tool, its the server where the process is running. That same process will also return the result of those tools back to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa434df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, ToolCall, ToolMessage\n",
    "from typing import Literal\n",
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621924ca",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a0b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(model=\"gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed0c4f0",
   "metadata": {},
   "source": [
    "Define the tool/action the LLM will have access to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b53a8e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def weather_tool(location: Literal[\"Chicago\", \"New York\", \"Los Angeles\"]) -> str:\n",
    "    \"\"\"\n",
    "    Get the current weather for a specified location.\n",
    "    Args:\n",
    "        location (str): The name of the city to get the weather for. \n",
    "                        Must be one of \"Chicago\", \"New York\", or \"Los Angeles\".\n",
    "    Returns:\n",
    "        str: A string describing the current weather in the specified location.\n",
    "    \"\"\"\n",
    "\n",
    "    weather_data = {\n",
    "        \"New York\": \"Sunny, 25°C\",\n",
    "        \"Los Angeles\": \"Cloudy, 22°C\",\n",
    "        \"Chicago\": \"Rainy, 18°C\"\n",
    "    }\n",
    "    return weather_data.get(location, \"Weather data not available for this location.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1a1a5d",
   "metadata": {},
   "source": [
    "Link the tools to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ae68a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([weather_tool])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fa0b59",
   "metadata": {},
   "source": [
    "Set prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e3ede1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant that can provide weather information for specific cities.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"What is the weather like in NYC?\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1df18b2",
   "metadata": {},
   "source": [
    "Initial call to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f867a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_with_tools.invoke(input=messages)\n",
    "#Adding the response to the prompt history\n",
    "messages.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0813db24",
   "metadata": {},
   "source": [
    "Check if the LLM wants to execute a tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08770b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(response.tool_calls) > 0:\n",
    "    for tool_call in response.tool_calls:\n",
    "        messages.append(\n",
    "            # Adding the tool call to the prompt history\n",
    "            ToolMessage(\n",
    "                name=tool_call[\"name\"],\n",
    "                content=weather_tool.run(tool_call[\"args\"][\"location\"]), #Executing the tool\n",
    "                tool_call_id=tool_call[\"id\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Calling the LLM again with the updated messages, containing the tool response\n",
    "    response = llm_with_tools.invoke(input=messages)\n",
    "    # Adding the final response to the prompt history\n",
    "    messages.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fa6392",
   "metadata": {},
   "source": [
    "Print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0946d022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant that can provide weather information for specific cities.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the weather like in NYC?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  weather_tool (call_4d03xCDEnFotRMjeg8w5UP4j)\n",
      " Call ID: call_4d03xCDEnFotRMjeg8w5UP4j\n",
      "  Args:\n",
      "    location: New York\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: weather_tool\n",
      "\n",
      "Sunny, 25°C\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The weather in New York City is currently sunny with a temperature of 25°C.\n"
     ]
    }
   ],
   "source": [
    "for msg in messages:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b659455",
   "metadata": {},
   "source": [
    "Notice the Tool Calls and Tool Messages before the response is generated.\n",
    "\n",
    "**NOTE:** Usage of tool means 2 LLM calls, one to know what tool is necessary and second one containg the result of the tool call"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
